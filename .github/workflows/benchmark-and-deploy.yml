name: Benchmark and Deploy

on:
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of iterations to run'
        required: false
        default: '20'
        type: string
      network_slow_4g:
        description: 'Enable Slow 4G network throttling'
        required: false
        default: false
        type: boolean
      network_no_throttling:
        description: 'Enable No throttling network condition'
        required: false
        default: true
        type: boolean
      cpu_4x_slowdown:
        description: 'Enable 4x CPU slowdown'
        required: false
        default: false
        type: boolean
      cpu_no_throttling:
        description: 'Enable No throttling CPU condition'
        required: false
        default: true
        type: boolean
      override_reports:
        description: 'Override existing reports instead of concatenating'
        required: false
        default: false
        type: boolean
      skip_benchmarking:
        description: 'Skip benchmarking and use existing results (for dashboard-only rebuilds)'
        required: false
        default: false
        type: boolean

jobs:
  benchmarking:
    if: ${{ github.event.inputs.skip_benchmarking != 'true' }}
    runs-on: ubuntu-latest
    outputs:
      results-artifact: ${{ steps.upload-results.outputs.artifact-id }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright
        run: npx playwright install --with-deps chromium

      - name: Build configuration from inputs
        id: build-config
        run: |
          # Ensure at least one condition is enabled (fallback to no_throttling)
          network_no_throttling="${{ github.event.inputs.network_no_throttling }}"
          network_slow_4g="${{ github.event.inputs.network_slow_4g }}"
          cpu_no_throttling="${{ github.event.inputs.cpu_no_throttling }}"
          cpu_4x_slowdown="${{ github.event.inputs.cpu_4x_slowdown }}"
          
          # If no network conditions selected, default to no_throttling
          if [ "$network_no_throttling" != "true" ] && [ "$network_slow_4g" != "true" ]; then
            network_no_throttling="true"
            echo "‚ö†Ô∏è  No network conditions selected, defaulting to no_throttling"
          fi
          
          # If no CPU conditions selected, default to no_throttling  
          if [ "$cpu_no_throttling" != "true" ] && [ "$cpu_4x_slowdown" != "true" ]; then
            cpu_no_throttling="true"
            echo "‚ö†Ô∏è  No CPU conditions selected, defaulting to no_throttling"
          fi
          
          # Build the complete config JSON with execution_matrix
          config_json=$(cat << EOF
          {
            "execution": {
              "iterations": ${{ github.event.inputs.iterations }}
            },
            "execution_matrix": {
              "network": {
                "slow_4g": {
                  "download_throughput": 500000,
                  "upload_throughput": 500000,
                  "latency": 400,
                  "enabled": $network_slow_4g
                },
                "no_throttling": {
                  "download_throughput": 0,
                  "upload_throughput": 0,
                  "latency": 0,
                  "enabled": $network_no_throttling
                }
              },
              "cpu": {
                "no_throttling": {
                  "rate": 1,
                  "enabled": $cpu_no_throttling
                },
                "4x_slowdown": {
                  "rate": 4,
                  "enabled": $cpu_4x_slowdown
                }
              }
            }
          }
          EOF
          )
          
          echo "Generated config:"
          echo "$config_json"
          echo "BENCHMARK_CONFIG<<EOF" >> $GITHUB_OUTPUT
          echo "$config_json" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Run benchmarking
        run: npm start
        env:
          MAGIC_BENCHMARKING_CONFIG: ${{ steps.build-config.outputs.BENCHMARK_CONFIG }}

      - name: Upload benchmark results
        id: upload-results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: dashboard/public/results/
          retention-days: 30

  build-and-deploy:
    runs-on: ubuntu-latest
    needs: [benchmarking]
    if: always() && (needs.benchmarking.result == 'success' || github.event.inputs.skip_benchmarking == 'true')
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dashboard dependencies
        run: cd dashboard && npm ci

      - name: Download benchmark results
        if: ${{ github.event.inputs.skip_benchmarking != 'true' }}
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: dashboard/public/results/

      - name: Download existing reports
        run: |
          echo "üì• Downloading existing reports from deployed site..."
          mkdir -p dashboard/public
          
          if [ "${{ github.event.inputs.override_reports }}" = "true" ]; then
            echo "üîÑ Override mode: Starting with empty reports"
            echo "[]" > dashboard/public/reports.json
          else
            echo "‚ûï Concat mode: Downloading existing reports"
            # Try to download existing reports.json from GitHub Pages
            if curl -f -s -o dashboard/public/reports.json "https://${{ github.repository_owner }}.github.io/magic-benchmarking/reports.json"; then
              echo "‚úÖ Downloaded existing reports.json"
              echo "üìä Existing reports count: $(cat dashboard/public/reports.json | jq length 2>/dev/null || echo 'unknown')"
            else
              echo "‚ÑπÔ∏è  No existing reports.json found (first run or site not deployed yet)"
              echo "[]" > dashboard/public/reports.json
            fi
          fi

      - name: Build dashboard
        run: cd dashboard && npm run build

      - name: Verify final reports
        run: |
          echo "üìä Final reports summary:"
          if [ -f "dashboard/public/reports.json" ]; then
            total_reports=$(cat dashboard/public/reports.json | jq length 2>/dev/null || echo 0)
            performance_reports=$(cat dashboard/public/reports.json | jq '[.[] | select(.type == "performance")] | length' 2>/dev/null || echo 0)
            network_reports=$(cat dashboard/public/reports.json | jq '[.[] | select(.type == "network")] | length' 2>/dev/null || echo 0)
            echo "  üìà Total reports: $total_reports"
            echo "  ‚ö° Performance reports: $performance_reports"
            echo "  üåê Network reports: $network_reports"
          else
            echo "  ‚ùå No reports.json found"
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: dashboard/out

      - name: Deploy to Pages
        uses: actions/deploy-pages@v4

  notify:
    runs-on: ubuntu-latest
    needs: [benchmarking, build-and-deploy]
    if: always()
    
    steps:
      - name: Notify completion
        run: |
          if [ "${{ needs.benchmarking.result }}" = "success" ] && [ "${{ needs.build-and-deploy.result }}" = "success" ]; then
            echo "‚úÖ Complete workflow succeeded!"
          elif [ "${{ github.event.inputs.skip_benchmarking }}" = "true" ] && [ "${{ needs.build-and-deploy.result }}" = "success" ]; then
            echo "‚úÖ Dashboard rebuild succeeded!"
          elif [ "${{ needs.benchmarking.result }}" = "success" ] && [ "${{ needs.build-and-deploy.result }}" != "success" ]; then
            echo "‚ö†Ô∏è  Benchmarking succeeded but deployment failed. You can re-run with skip_benchmarking=true"
          else
            echo "‚ùå Workflow failed. Check the logs for details."
          fi
